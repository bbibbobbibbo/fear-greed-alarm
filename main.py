import requests
import os
from datetime import datetime, date
import calendar
import re
from bs4 import BeautifulSoup
import json
import time

class RobustCNNFearGreedNotifier:
    def __init__(self):
        """
        ê²¬ê³ í•œ CNN Fear & Greed Index ì¶”ì¶œê¸°
        íŠ¹ì • ê°’ì— ì˜ì¡´í•˜ì§€ ì•Šê³  êµ¬ì¡° ê¸°ë°˜ìœ¼ë¡œ ì¶”ì¶œ
        """
        self.telegram_token = os.getenv('TELEGRAM_TOKEN')
        self.chat_id = os.getenv('TELEGRAM_CHAT_ID')
        self.cnn_url = "https://edition.cnn.com/markets/fear-and-greed"
        
        if not self.telegram_token or not self.chat_id:
            raise ValueError("TELEGRAM_TOKEN ë˜ëŠ” TELEGRAM_CHAT_IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        print("âœ… í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ì™„ë£Œ")
    
    def get_cnn_fear_greed_index(self):
        """
        CNN Fear & Greed Indexë¥¼ ê²¬ê³ í•˜ê²Œ ì¶”ì¶œ
        """
        try:
            print("ğŸ“Š CNN Fear & Greed Index ë°ì´í„° ìš”ì²­ ì¤‘...")
            
            # ë‹¤ì–‘í•œ User-Agentë¡œ ì‹œë„
            user_agents = [
                'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/121.0'
            ]
            
            for attempt, user_agent in enumerate(user_agents, 1):
                print(f"ğŸ”„ ì‹œë„ {attempt}/{len(user_agents)}: {user_agent[:50]}...")
                
                headers = {
                    'User-Agent': user_agent,
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                    'Accept-Language': 'en-US,en;q=0.9',
                    'Accept-Encoding': 'gzip, deflate, br',
                    'Connection': 'keep-alive',
                    'Upgrade-Insecure-Requests': '1',
                    'Cache-Control': 'no-cache',
                    'Pragma': 'no-cache',
                    'DNT': '1',
                    'Sec-Fetch-Dest': 'document',
                    'Sec-Fetch-Mode': 'navigate',
                    'Sec-Fetch-Site': 'none'
                }
                
                try:
                    response = requests.get(self.cnn_url, headers=headers, timeout=20)
                    response.raise_for_status()
                    
                    if len(response.text) > 50000:  # ì¶©ë¶„í•œ ë‚´ìš©ì´ ë¡œë“œë¨
                        print(f"âœ… CNN í˜ì´ì§€ ë¡œë“œ ì„±ê³µ ({len(response.text):,} ê¸€ì)")
                        break
                    else:
                        print(f"âš ï¸ í˜ì´ì§€ ë‚´ìš© ë¶€ì¡± ({len(response.text)} ê¸€ì)")
                        
                except Exception as e:
                    print(f"âŒ ì‹œë„ {attempt} ì‹¤íŒ¨: {e}")
                    if attempt < len(user_agents):
                        time.sleep(2)  # ì ì‹œ ëŒ€ê¸°
                        continue
                    else:
                        raise
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # ë‹¤ë‹¨ê³„ ì¶”ì¶œ ì‹œìŠ¤í…œ
            extraction_methods = [
                ('í•µì‹¬ íŒ¨í„´', self._extract_core_patterns),
                ('JavaScript ê°ì²´', self._extract_js_objects), 
                ('DOM êµ¬ì¡°', self._extract_dom_structure),
                ('ë©”íƒ€ë°ì´í„°', self._extract_metadata),
                ('ì»¨í…ìŠ¤íŠ¸ ë¶„ì„', self._extract_contextual),
                ('ë°±ì—… íŒ¨í„´', self._extract_backup_patterns)
            ]
            
            for method_name, extraction_func in extraction_methods:
                print(f"\nğŸ” {method_name} ì¶”ì¶œ ì‹œë„...")
                try:
                    result = extraction_func(response.text, soup)
                    if result and self._validate_score(result):
                        print(f"âœ… {method_name}ì—ì„œ ì„±ê³µ: {result['value']}")
                        result['extraction_method'] = method_name
                        return result
                    elif result:
                        print(f"âš ï¸ {method_name} ê²°ê³¼ ê²€ì¦ ì‹¤íŒ¨: {result.get('value', 'None')}")
                except Exception as e:
                    print(f"âŒ {method_name} ì˜¤ë¥˜: {e}")
                    continue
            
            print("âŒ ëª¨ë“  ì¶”ì¶œ ë°©ë²• ì‹¤íŒ¨")
            return None
            
        except Exception as e:
            print(f"âŒ CNN ë°ì´í„° ì¶”ì¶œ ì „ì²´ ì˜¤ë¥˜: {e}")
            return None
    
    def _extract_core_patterns(self, html_text, soup):
        """
        í•µì‹¬ Fear & Greed íŒ¨í„´ìœ¼ë¡œ ì¶”ì¶œ
        """
        # CNNì˜ ì‹¤ì œ êµ¬ì¡°ë¥¼ ë°˜ì˜í•œ ì •í™•í•œ íŒ¨í„´ë“¤
        core_patterns = [
            # JavaScript ë³€ìˆ˜/ê°ì²´ íŒ¨í„´
            r'(?:fear.*greed|fearGread|fearAndGreed).*?["\']?(?:score|value|index|current)["\']?\s*[:=]\s*["\']?(\d{1,2})["\']?',
            r'["\'](?:score|value|index)["\']?\s*[:=]\s*["\']?(\d{1,2})["\']?.*?(?:fear|greed)',
            
            # HTML ë°ì´í„° ì†ì„± íŒ¨í„´
            r'data-(?:fear-greed-)?(?:score|value|index|current)["\s]*=["\s]*(\d{1,2})["\s]*',
            r'(?:id|class)["\s]*=["\s]*[^"]*(?:fear.*greed|greed.*fear)[^"]*["\s]*[^>]*>.*?(\d{1,2})',
            
            # JSON êµ¬ì¡° íŒ¨í„´
            r'\{[^}]*(?:fear|greed)[^}]*["\'](?:score|value|index)["\']?\s*:\s*["\']?(\d{1,2})["\']?[^}]*\}',
            r'\{[^}]*["\'](?:score|value|index)["\']?\s*:\s*["\']?(\d{1,2})["\']?[^}]*(?:fear|greed)[^}]*\}',
            
            # ìŠ¤í¬ë¦½íŠ¸ ë‚´ ì§ì ‘ í• ë‹¹ íŒ¨í„´
            r'(?:var|let|const)\s+(?:fear.*greed|score|index)\s*=\s*["\']?(\d{1,2})["\']?',
            r'(?:fear.*greed|score|index)\s*=\s*["\']?(\d{1,2})["\']?',
        ]
        
        for i, pattern in enumerate(core_patterns, 1):
            try:
                matches = list(re.finditer(pattern, html_text, re.IGNORECASE | re.DOTALL))
                
                if matches:
                    print(f"  íŒ¨í„´ {i}: {len(matches)}ê°œ ë§¤ì¹˜")
                    
                    for match in matches:
                        score = int(match.group(1))
                        
                        # ì»¨í…ìŠ¤íŠ¸ ê²€ì¦
                        context = self._get_match_context(html_text, match, 300)
                        confidence = self._calculate_confidence(context, score)
                        
                        if confidence >= 0.7:  # 70% ì´ìƒ ì‹ ë¢°ë„
                            print(f"    âœ… ë†’ì€ ì‹ ë¢°ë„ ì ìˆ˜: {score} (ì‹ ë¢°ë„: {confidence:.2f})")
                            return {
                                'value': score,
                                'classification': self._get_classification(score),
                                'source': 'CNN Fear & Greed Index',
                                'confidence': confidence,
                                'pattern_used': f'core_pattern_{i}',
                                'context_preview': context[:100] + '...'
                            }
                        elif confidence >= 0.4:
                            print(f"    ğŸ“Š ì¤‘ê°„ ì‹ ë¢°ë„ ì ìˆ˜: {score} (ì‹ ë¢°ë„: {confidence:.2f})")
                            # ì¼ë‹¨ ì €ì¥í•´ë‘ê³  ë” ì¢‹ì€ ê²ƒì´ ì—†ìœ¼ë©´ ì‚¬ìš©
                            
            except Exception as e:
                print(f"  íŒ¨í„´ {i} ì˜¤ë¥˜: {e}")
                continue
        
        return None
    
    def _extract_js_objects(self, html_text, soup):
        """
        JavaScript ê°ì²´ì—ì„œ ì¶”ì¶œ
        """
        script_tags = soup.find_all('script')
        print(f"  ì´ {len(script_tags)}ê°œ ìŠ¤í¬ë¦½íŠ¸ íƒœê·¸ ë¶„ì„...")
        
        # Fear & Greed ê´€ë ¨ ìŠ¤í¬ë¦½íŠ¸ë§Œ í•„í„°ë§
        relevant_scripts = []
        for script in script_tags:
            if script.string:
                script_lower = script.string.lower()
                if any(keyword in script_lower for keyword in ['fear', 'greed', 'market', 'index']):
                    relevant_scripts.append(script.string)
        
        print(f"  ê´€ë ¨ ìŠ¤í¬ë¦½íŠ¸ {len(relevant_scripts)}ê°œ ë°œê²¬")
        
        for i, script_content in enumerate(relevant_scripts):
            try:
                # JSON ê°ì²´ íŒ¨í„´ ì°¾ê¸°
                json_patterns = [
                    r'\{[^{}]*(?:fear|greed)[^{}]*\}',
                    r'\{[^{}]*(?:score|value|index)[^{}]*\}',
                    r'(?:fearGreed|fearAndGreed|marketSentiment)\s*[:=]\s*(\{[^}]+\})',
                ]
                
                for pattern in json_patterns:
                    matches = re.finditer(pattern, script_content, re.IGNORECASE | re.DOTALL)
                    
                    for match in matches:
                        try:
                            # JSON íŒŒì‹± ì‹œë„
                            json_str = match.group(1) if match.groups() else match.group(0)
                            
                            # JSON ì •ë¦¬ (JavaScript ê°ì²´ë¥¼ JSONìœ¼ë¡œ ë³€í™˜)
                            json_str = re.sub(r'([{,]\s*)([a-zA-Z_$][a-zA-Z0-9_$]*)\s*:', r'\1"\2":', json_str)
                            json_str = re.sub(r"'([^']*)'", r'"\1"', json_str)
                            
                            data = json.loads(json_str)
                            score = self._find_score_in_data(data)
                            
                            if score and 0 <= score <= 100:
                                print(f"    âœ… JSON ê°ì²´ì—ì„œ ì ìˆ˜ ë°œê²¬: {score}")
                                return {
                                    'value': score,
                                    'classification': self._get_classification(score),
                                    'source': 'CNN Fear & Greed Index',
                                    'confidence': 0.9,
                                    'extraction_method': 'js_object'
                                }
                                
                        except json.JSONDecodeError:
                            # JSON íŒŒì‹± ì‹¤íŒ¨ëŠ” ì •ìƒì , ê³„ì† ì§„í–‰
                            continue
                            
            except Exception as e:
                print(f"  ìŠ¤í¬ë¦½íŠ¸ {i} ë¶„ì„ ì˜¤ë¥˜: {e}")
                continue
        
        return None
    
    def _extract_dom_structure(self, html_text, soup):
        """
        DOM êµ¬ì¡° ê¸°ë°˜ ì¶”ì¶œ
        """
        # Fear & Greed ê´€ë ¨ í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ ìš”ì†Œë“¤ ì°¾ê¸°
        fear_greed_elements = soup.find_all(text=re.compile(r'fear.*greed|greed.*fear', re.IGNORECASE))
        print(f"  Fear/Greed í…ìŠ¤íŠ¸ ìš”ì†Œ {len(fear_greed_elements)}ê°œ ë°œê²¬")
        
        candidates = []
        
        for element in fear_greed_elements:
            try:
                parent = element.parent
                if not parent:
                    continue
                
                # ë¶€ëª¨ì™€ í˜•ì œ ìš”ì†Œë“¤ì—ì„œ ìˆ«ì ì°¾ê¸°
                for level in range(3):  # 3ë‹¨ê³„ê¹Œì§€ ì˜¬ë¼ê°€ë©´ì„œ í™•ì¸
                    if not parent:
                        break
                    
                    # í˜„ì¬ ë ˆë²¨ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ ìˆ˜ì§‘
                    all_text = ' '.join(parent.get_text(separator=' ', strip=True).split())
                    
                    # ìˆ«ì íŒ¨í„´ ì°¾ê¸°
                    number_patterns = [
                        r'\b(\d{1,2})\b(?!\d)',  # ê¸°ë³¸ 1-2ìë¦¬ ìˆ«ì
                        r'(\d{1,2})(?:\.\d+)?',  # ì†Œìˆ˜ì  í¬í•¨
                        r'(?:score|index|value).*?(\d{1,2})',  # í‚¤ì›Œë“œ ë’¤ ìˆ«ì
                        r'(\d{1,2}).*?(?:score|index|value)',  # ìˆ«ì ë’¤ í‚¤ì›Œë“œ
                    ]
                    
                    for pattern in number_patterns:
                        numbers = re.findall(pattern, all_text)
                        for num_str in numbers:
                            try:
                                score = int(float(num_str))
                                if 0 <= score <= 100:
                                    # ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ í‰ê°€
                                    context_quality = self._evaluate_context_quality(all_text, score)
                                    candidates.append({
                                        'score': score,
                                        'context': all_text[:200],
                                        'quality': context_quality,
                                        'level': level
                                    })
                            except ValueError:
                                continue
                    
                    parent = parent.parent
                    
            except Exception as e:
                print(f"  DOM ìš”ì†Œ ë¶„ì„ ì˜¤ë¥˜: {e}")
                continue
        
        # ê°€ì¥ í’ˆì§ˆ ì¢‹ì€ í›„ë³´ ì„ íƒ
        if candidates:
            best_candidate = max(candidates, key=lambda x: x['quality'])
            print(f"    âœ… DOMì—ì„œ ìµœì  ì ìˆ˜: {best_candidate['score']} (í’ˆì§ˆ: {best_candidate['quality']:.2f})")
            
            if best_candidate['quality'] >= 0.6:
                return {
                    'value': best_candidate['score'],
                    'classification': self._get_classification(best_candidate['score']),
                    'source': 'CNN Fear & Greed Index',
                    'confidence': best_candidate['quality'],
                    'extraction_method': 'dom_structure'
                }
        
        return None
    
    def _extract_metadata(self, html_text, soup):
        """
        ë©”íƒ€ë°ì´í„°ì—ì„œ ì¶”ì¶œ
        """
        # ë©”íƒ€ íƒœê·¸ë“¤ í™•ì¸
        meta_tags = soup.find_all('meta')
        
        for meta in meta_tags:
            content = meta.get('content', '')
            name = meta.get('name', '')
            property_name = meta.get('property', '')
            
            all_meta_text = f"{name} {property_name} {content}".lower()
            
            if any(keyword in all_meta_text for keyword in ['fear', 'greed', 'market', 'sentiment']):
                numbers = re.findall(r'\b(\d{1,2})\b', content)
                for num_str in numbers:
                    score = int(num_str)
                    if 0 <= score <= 100:
                        print(f"    âœ… ë©”íƒ€ë°ì´í„°ì—ì„œ ì ìˆ˜: {score}")
                        return {
                            'value': score,
                            'classification': self._get_classification(score),
                            'source': 'CNN Fear & Greed Index',
                            'confidence': 0.7,
                            'extraction_method': 'metadata'
                        }
        
        return None
    
    def _extract_contextual(self, html_text, soup):
        """
        ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ê¸°ë°˜ ì¶”ì¶œ
        """
        # í˜ì´ì§€ë¥¼ ì¤„ ë‹¨ìœ„ë¡œ ë¶„ì„
        lines = html_text.split('\n')
        
        for i, line in enumerate(lines):
            line_lower = line.lower()
            
            # Fear & Greed ê´€ë ¨ ì¤„ ì°¾ê¸°
            if any(keyword in line_lower for keyword in ['fear', 'greed']):
                # ì•ë’¤ 5ì¤„ì”© ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘
                context_start = max(0, i - 5)
                context_end = min(len(lines), i + 6)
                context_lines = lines[context_start:context_end]
                context = ' '.join(context_lines)
                
                # ì´ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ê°€ì¥ ì ì ˆí•œ ìˆ«ì ì°¾ê¸°
                numbers = re.findall(r'\b(\d{1,2})\b', context)
                
                if numbers:
                    # ìˆ«ìë“¤ì˜ ì ì ˆì„± í‰ê°€
                    number_scores = []
                    for num_str in numbers:
                        score = int(num_str)
                        if 0 <= score <= 100:
                            appropriateness = self._evaluate_number_appropriateness(context, score, line_lower)
                            number_scores.append((score, appropriateness))
                    
                    if number_scores:
                        # ê°€ì¥ ì ì ˆí•œ ì ìˆ˜ ì„ íƒ
                        best_score, best_appropriateness = max(number_scores, key=lambda x: x[1])
                        
                        if best_appropriateness >= 0.5:
                            print(f"    âœ… ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì ìˆ˜: {best_score} (ì ì ˆì„±: {best_appropriateness:.2f})")
                            return {
                                'value': best_score,
                                'classification': self._get_classification(best_score),
                                'source': 'CNN Fear & Greed Index',
                                'confidence': best_appropriateness,
                                'extraction_method': 'contextual'
                            }
        
        return None
    
    def _extract_backup_patterns(self, html_text, soup):
        """
        ë°±ì—… íŒ¨í„´ë“¤ë¡œ ìµœí›„ ì‹œë„
        """
        # ë§¤ìš° ê´€ëŒ€í•œ íŒ¨í„´ë“¤ (false positive ìœ„í—˜ ìˆì§€ë§Œ ë§ˆì§€ë§‰ ìˆ˜ë‹¨)
        backup_patterns = [
            r'(?:current|today|now).*?(\d{1,2})(?!\d)',
            r'(\d{1,2})(?!\d).*?(?:current|today|now)',
            r'market.*?(\d{1,2})(?!\d)',
            r'(\d{1,2})(?!\d).*?market',
            r'index.*?(\d{1,2})(?!\d)',
            r'(\d{1,2})(?!\d).*?index',
        ]
        
        page_numbers = []
        
        for pattern in backup_patterns:
            matches = re.finditer(pattern, html_text, re.IGNORECASE)
            for match in matches:
                score = int(match.group(1))
                if 20 <= score <= 90:  # ë” ì œí•œì ì¸ ë²”ìœ„
                    context = self._get_match_context(html_text, match, 200)
                    if any(keyword in context.lower() for keyword in ['fear', 'greed', 'market', 'emotion']):
                        page_numbers.append(score)
        
        if page_numbers:
            # ê°€ì¥ ìì£¼ ë‚˜íƒ€ë‚˜ëŠ” ìˆ«ì ì„ íƒ
            from collections import Counter
            most_common = Counter(page_numbers).most_common(1)
            if most_common:
                score = most_common[0][0]
                print(f"    âœ… ë°±ì—… íŒ¨í„´ì—ì„œ ì ìˆ˜: {score} (ë¹ˆë„: {most_common[0][1]})")
                return {
                    'value': score,
                    'classification': self._get_classification(score),
                    'source': 'CNN Fear & Greed Index',
                    'confidence': 0.4,
                    'extraction_method': 'backup_pattern'
                }
        
        return None
    
    def _get_match_context(self, text, match, context_size):
        """ë§¤ì¹˜ ì£¼ë³€ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        start = max(0, match.start() - context_size)
        end = min(len(text), match.end() + context_size)
        return text[start:end]
    
    def _calculate_confidence(self, context, score):
        """ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì‹ ë¢°ë„ ê³„ì‚°"""
        confidence = 0.0
        context_lower = context.lower()
        
        # Fear & Greed í‚¤ì›Œë“œ
        if 'fear' in context_lower and 'greed' in context_lower:
            confidence += 0.4
        elif 'fear' in context_lower or 'greed' in context_lower:
            confidence += 0.2
        
        # ê´€ë ¨ í‚¤ì›Œë“œë“¤
        keywords = ['index', 'market', 'sentiment', 'emotion', 'score', 'current']
        keyword_count = sum(1 for keyword in keywords if keyword in context_lower)
        confidence += min(keyword_count * 0.1, 0.3)
        
        # ì ìˆ˜ ë²”ìœ„ í•©ë¦¬ì„±
        if 20 <= score <= 80:
            confidence += 0.2
        elif 10 <= score <= 90:
            confidence += 0.1
        
        # ìˆ«ìê°€ ì ì ˆí•œ ìœ„ì¹˜ì— ìˆëŠ”ì§€
        if re.search(r'(?:score|index|value).*?' + str(score), context_lower):
            confidence += 0.2
        elif re.search(str(score) + r'.*?(?:score|index|value)', context_lower):
            confidence += 0.1
        
        return min(confidence, 1.0)
    
    def _evaluate_context_quality(self, context, score):
        """ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ í‰ê°€"""
        return self._calculate_confidence(context, score)
    
    def _evaluate_number_appropriateness(self, context, score, trigger_line):
        """ìˆ«ìì˜ ì ì ˆì„± í‰ê°€"""
        appropriateness = 0.0
        
        # Fear & Greed íŠ¸ë¦¬ê±° ë¼ì¸ì— ë” ë†’ì€ ì ìˆ˜
        if 'fear' in trigger_line and 'greed' in trigger_line:
            appropriateness += 0.5
        
        # ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ
        appropriateness += self._calculate_confidence(context, score) * 0.5
        
        return appropriateness
    
    def _find_score_in_data(self, data):
        """JSON ë°ì´í„°ì—ì„œ ì ìˆ˜ ì°¾ê¸°"""
        if isinstance(data, dict):
            for key, value in data.items():
                if any(keyword in key.lower() for keyword in ['score', 'index', 'value', 'fear', 'greed']):
                    if isinstance(value, (int, str)) and str(value).isdigit():
                        score = int(value)
                        if 0 <= score <= 100:
                            return score
                
                result = self._find_score_in_data(value)
                if result:
                    return result
        elif isinstance(data, list):
            for item in data:
                result = self._find_score_in_data(item)
                if result:
                    return result
        
        return None
    
    def _validate_score(self, result):
        """ì¶”ì¶œëœ ì ìˆ˜ì˜ ìœ íš¨ì„± ê²€ì¦"""
        if not result or 'value' not in result:
            return False
        
        score = result['value']
        
        # ê¸°ë³¸ ë²”ìœ„ ì²´í¬
        if not (0 <= score <= 100):
            return False
        
        # ì‹ ë¢°ë„ ì²´í¬
        confidence = result.get('confidence', 0.5)
        if confidence < 0.3:
            return False
        
        return True
    
    def _get_classification(self, value):
        """ì ìˆ˜ ë¶„ë¥˜"""
        if value <= 25:
            return "Extreme Fear"
        elif value <= 45:
            return "Fear"
        elif value <= 55:
            return "Neutral"
        elif value <= 75:
            return "Greed"
        else:
            return "Extreme Greed"
    
    def interpret_index(self, value):
        """ì§€ìˆ˜ í•´ì„"""
        if value <= 25:
            interpretation = "ğŸ”´ ê·¹ë„ì˜ ê³µí¬ (Extreme Fear)"
            advice = "ğŸ“ˆ ì‹œì¥ì´ ê·¹ë„ë¡œ ë‘ë ¤ì›Œí•˜ê³  ìˆìŠµë‹ˆë‹¤. ì›Œë Œ ë²„í•ì˜ ì¡°ì–¸ëŒ€ë¡œ 'ë‚¨ì´ ë‘ë ¤ì›Œí•  ë•Œ íƒìš•ìŠ¤ëŸ¬ì›Œí•˜ë¼'ëŠ” ì‹œì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            emoji = "ğŸ˜±"
            strategy = "ğŸ’° ìš°ëŸ‰ ëŒ€í˜•ì£¼ ì ì§„ì  ë§¤ìˆ˜ ê³ ë ¤"
        elif value <= 45:
            interpretation = "ğŸŸ  ê³µí¬ (Fear)"
            advice = "ğŸ“Š ì‹œì¥ì— ê³µí¬ ì‹¬ë¦¬ê°€ í™•ì‚°ë˜ê³  ìˆìŠµë‹ˆë‹¤. ê°€ì¹˜ì£¼ë“¤ì˜ ë°¸ë¥˜ì—ì´ì…˜ì„ í™•ì¸í•˜ê³  ì €í‰ê°€ëœ ìš°ëŸ‰ê¸°ì—…ì„ ì°¾ì•„ë³´ì„¸ìš”."
            emoji = "ğŸ˜°"
            strategy = "ğŸ¯ ê°€ì¹˜ì£¼ ì¤‘ì‹¬ ì„ ë³„ì  ë§¤ìˆ˜"
        elif value <= 55:
            interpretation = "ğŸŸ¡ ì¤‘ë¦½ (Neutral)"
            advice = "âš–ï¸ ì‹œì¥ì´ ê· í˜•ì„ ì´ë£¨ê³  ìˆìŠµë‹ˆë‹¤. í‰ì†Œì™€ ê°™ì´ ê¾¸ì¤€í•œ ë¶„ì‚°íˆ¬ìì™€ ì •ê¸°ì ë¦½ì„ ìœ ì§€í•˜ì„¸ìš”."
            emoji = "ğŸ˜"
            strategy = "ğŸ”„ ì •ê¸°íˆ¬ì ë° ë¦¬ë°¸ëŸ°ì‹±"
        elif value <= 75:
            interpretation = "ğŸŸ¢ íƒìš• (Greed)"
            advice = "âš ï¸ ì‹œì¥ì— íƒìš•ì´ ì»¤ì§€ê³  ìˆìŠµë‹ˆë‹¤. ê³ í‰ê°€ëœ ì¢…ëª©ë“¤ì„ ì ê²€í•˜ê³  ì‹ ì¤‘í•œ ë§¤ìˆ˜ ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤."
            emoji = "ğŸ˜Š"
            strategy = "ğŸš¨ ë³´ìˆ˜ì  ì ‘ê·¼, í˜„ê¸ˆ ë¹„ì¤‘ í™•ëŒ€"
        else:
            interpretation = "ğŸ”¥ ê·¹ë„ì˜ íƒìš• (Extreme Greed)"
            advice = "ğŸš¨ ì‹œì¥ì´ ê³¼ì—´ë˜ì—ˆìŠµë‹ˆë‹¤. ì¼ë¶€ ì°¨ìµì‹¤í˜„ì„ ê³ ë ¤í•˜ê³  ë‹¤ìŒ ê¸°íšŒë¥¼ ìœ„í•´ í˜„ê¸ˆì„ ì¤€ë¹„í•˜ëŠ” ê²ƒì´ ì¢‹ê² ìŠµë‹ˆë‹¤."
            emoji = "ğŸ¤‘"
            strategy = "ğŸ’¸ ì°¨ìµì‹¤í˜„ ë° í˜„ê¸ˆ í™•ë³´"
            
        return interpretation, advice, emoji, strategy
    
    def is_us_market_closed(self):
        """ë¯¸êµ­ ì‹œì¥ íœ´ì¥ì¼ í™•ì¸"""
        today = datetime.now()
        weekday = today.weekday()
        
        if weekday >= 5:  # ì£¼ë§
            return True
            
        month, day = today.month, today.day
        holidays = [(1, 1), (7, 4), (12, 25)]
        
        return (month, day) in holidays
    
    def should_send_message(self):
        """ë©”ì‹œì§€ ì „ì†¡ ì—¬ë¶€"""
        if self.is_us_market_closed():
            print("ğŸ‡ºğŸ‡¸ ë¯¸êµ­ ì£¼ì‹ì‹œì¥ íœ´ì¥ì¼ì´ë¯€ë¡œ ì•Œë¦¼ì„ ì „ì†¡í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return False
        return True
    
    def send_telegram_message(self, message):
        """í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ì „ì†¡"""
        try:
            print("ğŸ“¤ í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ì „ì†¡ ì¤‘...")
            
            url = f"https://api.telegram.org/bot{self.telegram_token}/sendMessage"
            payload = {
                'chat_id': self.chat_id,
                'text': message,
                'parse_mode': 'HTML'
            }
            
            response = requests.post(url, data=payload, timeout=15)
            response.raise_for_status()
            
            print("âœ… í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ì „ì†¡ ì„±ê³µ!")
            return True
            
        except Exception as e:
            print(f"âŒ í…”ë ˆê·¸ë¨ ì „ì†¡ ì‹¤íŒ¨: {e}")
            return False
    
    def create_daily_message(self):
        """ì¼ì¼ ë©”ì‹œì§€ ìƒì„±"""
        fear_greed_data = self.get_cnn_fear_greed_index()
        
        if not fear_greed_data:
            return "âŒ CNN Fear & Greed Index ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´íŠ¸ êµ¬ì¡°ê°€ ë³€ê²½ë˜ì—ˆê±°ë‚˜ ì ‘ì†ì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        
        current_time = datetime.now().strftime("%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„")
        interpretation, advice, emoji, strategy = self.interpret_index(fear_greed_data['value'])
        
        value = fear_greed_data['value']
        filled_bars = value // 10
        progress_bar = "ğŸŸ©" * filled_bars + "â¬œ" * (10 - filled_bars)
        
        confidence = fear_greed_data.get('confidence', 0.5)
        confidence_text = f"ì‹ ë¢°ë„ {confidence:.0%}"
        
        extraction_method = fear_greed_data.get('extraction_method', 'ì•Œ ìˆ˜ ì—†ìŒ')
        
        message = f"""
ğŸ‡ºğŸ‡¸ <b>ë¯¸êµ­ ì£¼ì‹ì‹œì¥ Fear & Greed Index</b> {emoji}
ğŸ“… {current_time} ({confidence_text})

ğŸ“Š <b>í˜„ì¬ ì§€ìˆ˜: {fear_greed_data['value']}/100</b>
{progress_bar}
{interpretation}

ğŸ’¡ <b>ê°€ì¹˜íˆ¬ìì ê°€ì´ë“œ</b>
{advice}

ğŸ¯ <b>íˆ¬ì ì „ëµ</b>
{strategy}

ğŸ“ˆ <b>CNN Fear & Greed Index êµ¬ì„±ìš”ì†Œ</b>
â€¢ ì£¼ì‹ ê°€ê²© ëª¨ë©˜í…€ â€¢ ì£¼ì‹ ê°€ê²© ê°•ë„ â€¢ ì‹œì¥ í­
â€¢ í’‹/ì½œ ì˜µì…˜ ë¹„ìœ¨ â€¢ ì •í¬ë³¸ë“œ ìˆ˜ìš” â€¢ VIX ë³€ë™ì„±
â€¢ ì•ˆì „ìì‚° ìˆ˜ìš”

ğŸ“š <b>ì›Œë Œ ë²„í•ì˜ íˆ¬ì ì›ì¹™</b>
"ë‹¤ë¥¸ ì‚¬ëŒì´ íƒìš•ìŠ¤ëŸ¬ìš¸ ë•Œ ë‘ë ¤ì›Œí•˜ê³ , 
ë‹¤ë¥¸ ì‚¬ëŒì´ ë‘ë ¤ì›Œí•  ë•Œ íƒìš•ìŠ¤ëŸ¬ì›Œí•˜ë¼"

ğŸ”— <b>ë°ì´í„° ì¶œì²˜:</b> CNN Fear & Greed Index
ğŸ” <b>ì¶”ì¶œ ë°©ë²•:</b> {extraction_method}

ğŸ¤– <i>ê²¬ê³ í•œ CNN ìŠ¤í¬ë˜í¼ v2.0 (ë¯¸êµ­ ì‹œì¥ ê°œì¥ì¼ë§Œ)</i>
        """
        
        return message.strip()
    
    def run(self):
        """ë©”ì¸ ì‹¤í–‰"""
        print("=" * 60)
        print("ğŸ‡ºğŸ‡¸ ê²¬ê³ í•œ CNN Fear & Greed Index ìŠ¤í¬ë˜í¼ ì‹¤í–‰")
        print("=" * 60)
        
        try:
            if not self.should_send_message():
                print("âœ… íœ´ì¥ì¼ í™•ì¸ - ì•Œë¦¼ ê±´ë„ˆë›°ê¸°")
                return True
            
            message = self.create_daily_message()
            success = self.send_telegram_message(message)
            
            if success:
                print("âœ… CNN ì§€ìˆ˜ ì¶”ì¶œ ë° ì „ì†¡ ì™„ë£Œ!")
                return True
            else:
                print("âŒ ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            print(f"âŒ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            return False

def main():
    try:
        notifier = RobustCNNFearGreedNotifier()
        success = notifier.run()
        
        if success:
            print("\nğŸ‰ ê²¬ê³ í•œ CNN ìŠ¤í¬ë˜í¼ ì„±ê³µ!")
        else:
            print("\nğŸ’¥ ì‹¤í–‰ ì‹¤íŒ¨!")
            exit(1)
            
    except Exception as e:
        print(f"\nğŸ’¥ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
        exit(1)

if __name__ == "__main__":
    main()
